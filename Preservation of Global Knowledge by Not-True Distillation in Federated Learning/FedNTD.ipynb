{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q flwr[simulation]\n",
    "%pip install flwr_datasets[vision]\n",
    "%pip install matplotlib\n",
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network architecture.\n",
    "    As described in McMahan 2017 paper :\n",
    "    [Communication-Efficient Learning of Deep Networks from\n",
    "    Decentralized Data] (https://arxiv.org/pdf/1602.05629.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the CNN.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input Tensor that will pass through the network\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The resulting Tensor after it has passed through the network\n",
    "        \"\"\"\n",
    "        output_tensor = F.relu(self.conv1(input_tensor))\n",
    "        output_tensor = self.pool(output_tensor)\n",
    "        output_tensor = F.relu(self.conv2(output_tensor))\n",
    "        output_tensor = self.pool(output_tensor)\n",
    "        output_tensor = torch.flatten(output_tensor, 1)\n",
    "        output_tensor = F.relu(self.fc1(output_tensor))\n",
    "        output_tensor = self.fc2(output_tensor)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTDLoss(nn.Module):\n",
    "    \"\"\"Not-true Distillation Loss.\n",
    "    As described in:\n",
    "    [Preservation of the Global Knowledge by Not-True Distillation in Federated Learning](https://arxiv.org/pdf/2106.03097.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10, tau=3, beta=1):\n",
    "        super(NTDLoss, self).__init__()\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        self.KLDiv = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        self.num_classes = num_classes\n",
    "        self.tau = tau\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, local_logits, targets, global_logits):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        ce_loss = self.CE(local_logits, targets)\n",
    "        local_logits = self._refine_as_not_true(local_logits, targets)\n",
    "        local_probs = F.log_softmax(local_logits / self.tau, dim=1)\n",
    "        with torch.no_grad():\n",
    "            global_logits = self._refine_as_not_true(global_logits, targets)\n",
    "            global_probs = torch.softmax(global_logits / self.tau, dim=1)\n",
    "\n",
    "        ntd_loss = (self.tau**2) * self.KLDiv(local_probs, global_probs)\n",
    "\n",
    "        loss = ce_loss + self.beta * ntd_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _refine_as_not_true(\n",
    "        self,\n",
    "        logits,\n",
    "        targets,\n",
    "    ):\n",
    "        nt_positions = torch.arange(0, self.num_classes).to(logits.device)\n",
    "        nt_positions = nt_positions.repeat(logits.size(0), 1)\n",
    "        nt_positions = nt_positions[nt_positions[:, :] != targets.view(-1, 1)]\n",
    "        nt_positions = nt_positions.view(-1, self.num_classes - 1)\n",
    "\n",
    "        logits = torch.gather(logits, 1, nt_positions)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( \n",
    "    net: nn.Module,\n",
    "    trainloader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    device: torch.device,\n",
    "    epochs: int,\n",
    "    tau: float,\n",
    "    beta: float,\n",
    "    num_classes: int,\n",
    ") -> None:\n",
    "    \"\"\"Train the network on the training set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : nn.Module\n",
    "        The neural network to train.\n",
    "    trainloader : DataLoader\n",
    "        The DataLoader containing the data to train the network on.\n",
    "    device : torch.device\n",
    "        The device on which the model should be trained, either 'cpu' or 'cuda'.\n",
    "    epochs : int\n",
    "        The number of epochs the model should be trained for.\n",
    "    learning_rate : float\n",
    "        The learning rate for the SGD optimizer.\n",
    "    tau : float\n",
    "        Parameter for tau.\n",
    "    beta : float\n",
    "        Parameter for beta.\n",
    "    \"\"\"\n",
    "    criterion = NTDLoss(num_classes=num_classes, tau=tau, beta=beta)\n",
    "    global_net = Net(num_classes).to(device=device)\n",
    "    global_net.load_state_dict(net.state_dict())\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            local_logits = net(images)\n",
    "            with torch.no_grad():\n",
    "                global_logits = global_net(images)\n",
    "            loss = criterion(local_logits, labels, global_logits)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def test(\n",
    "    net: nn.Module, testloader: DataLoader, device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate the network on the entire test set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : nn.Module\n",
    "        The neural network to test.\n",
    "    testloader : DataLoader\n",
    "        The DataLoader containing the data to test the network on.\n",
    "    device : torch.device\n",
    "        The device on which the model should be tested, either 'cpu' or 'cuda'.\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float, float]\n",
    "        The loss and the accuracy of the input model on the given data.\n",
    "    \"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    if len(testloader.dataset) == 0:\n",
    "        raise ValueError(\"Testloader can't be 0, exiting...\")\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transforms(batch):\n",
    "    \"\"\"Get transformation for MNIST dataset.\"\"\"\n",
    "    transforms = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Callable, Dict, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from flwr.common.typing import NDArrays, Scalar\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "def get_evaluate_fn(\n",
    "    centralized_testset: Dataset,\n",
    ") -> Callable[\n",
    "    [int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]\n",
    "]:\n",
    "    \"\"\"Generate the function for centralized evaluation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    centralized_testset : Dataset\n",
    "        The dataset to test the model with.\n",
    "    Returns\n",
    "    -------\n",
    "    Callable[ [int, NDArrays, Dict[str, Scalar]],\n",
    "                Optional[Tuple[float, Dict[str, Scalar]]] ]\n",
    "        The centralized evaluation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def evaluate_fn(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        model = Net(num_classes=10)\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        testset = centralized_testset.with_transform(apply_transforms)\n",
    "        testloader = DataLoader(testset, batch_size=50)\n",
    "        loss, accuracy = test(model, testloader, device)\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from secrets import token_hex\n",
    "from typing import Dict, Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from flwr.server.history import History\n",
    "\n",
    "\n",
    "def plot_metric_from_history(\n",
    "    hist: History,\n",
    "    save_plot_path: str,\n",
    "    suffix: Optional[str] = \"\",\n",
    ") -> None:\n",
    "    \"\"\"Plot from Flower server History.\n",
    "    Parameters\n",
    "    ----------\n",
    "    hist : History\n",
    "        Object containing evaluation for all rounds.\n",
    "    save_plot_path : str\n",
    "        Folder to save the plot to.\n",
    "    suffix: Optional[str]\n",
    "        Optional string to add at the end of the filename for the plot.\n",
    "    \"\"\"\n",
    "    metric_type = \"centralized\"\n",
    "    metric_dict = (\n",
    "        hist.metrics_centralized\n",
    "        if metric_type == \"centralized\"\n",
    "        else hist.metrics_distributed\n",
    "    )\n",
    "    _, values = zip(*metric_dict[\"accuracy\"])\n",
    "\n",
    "    # let's extract centralised loss (main metric reported in FedProx paper)\n",
    "    rounds_loss, values_loss = zip(*hist.losses_centralized)\n",
    "\n",
    "    _, axs = plt.subplots(nrows=2, ncols=1, sharex=\"row\")\n",
    "    axs[0].plot(np.asarray(rounds_loss), np.asarray(values_loss))\n",
    "    axs[1].plot(np.asarray(rounds_loss), np.asarray(values))\n",
    "\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "    # plt.title(f\"{metric_type.capitalize()} Validation - MNIST\")\n",
    "    plt.xlabel(\"Rounds\")\n",
    "    # plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(Path(save_plot_path) / Path(f\"{metric_type}_metrics{suffix}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_results_as_pickle(\n",
    "    history: History,\n",
    "    file_path: Union[str, Path],\n",
    "    extra_results: Optional[Dict] = None,\n",
    "    default_filename: str = \"results.pkl\",\n",
    ") -> None:\n",
    "    \"\"\"Save results from simulation to pickle.\n",
    "    Parameters\n",
    "    ----------\n",
    "    history: History\n",
    "        History returned by start_simulation.\n",
    "    file_path: Union[str, Path]\n",
    "        Path to file to create and store both history and extra_results.\n",
    "        If path is a directory, the default_filename will be used.\n",
    "        path doesn't exist, it will be created. If file exists, a\n",
    "        randomly generated suffix will be added to the file name. This\n",
    "        is done to avoid overwritting results.\n",
    "    extra_results : Optional[Dict]\n",
    "        A dictionary containing additional results you would like\n",
    "        to be saved to disk. Default: {} (an empty dictionary)\n",
    "    default_filename: Optional[str]\n",
    "        File used by default if file_path points to a directory instead\n",
    "        to a file. Default: \"results.pkl\"\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "\n",
    "    # ensure path exists\n",
    "    path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    def _add_random_suffix(path_: Path):\n",
    "        \"\"\"Add a randomly generated suffix to the file name (so it doesn't.\n",
    "        overwrite the file).\n",
    "        \"\"\"\n",
    "        print(f\"File `{path_}` exists! \")\n",
    "        suffix = token_hex(4)\n",
    "        print(f\"New results to be saved with suffix: {suffix}\")\n",
    "        return path_.parent / (path_.stem + \"_\" + suffix + \".pkl\")\n",
    "\n",
    "    def _complete_path_with_default_name(path_: Path):\n",
    "        \"\"\"Append the default file name to the path.\"\"\"\n",
    "        print(\"Using default filename\")\n",
    "        return path_ / default_filename\n",
    "\n",
    "    if path.is_dir():\n",
    "        path = _complete_path_with_default_name(path)\n",
    "\n",
    "    if path.is_file():\n",
    "        # file exists already\n",
    "        path = _add_random_suffix(path)\n",
    "\n",
    "    print(f\"Results will be saved into: {path}\")\n",
    "\n",
    "    data = {\"history\": history}\n",
    "    if extra_results is not None:\n",
    "        data = {**data, **extra_results}\n",
    "\n",
    "    # save results to pickle\n",
    "    with open(str(path), \"wb\") as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict\n",
    "\n",
    "import flwr as fl\n",
    "import torch\n",
    "from flwr.common import NDArrays, Scalar\n",
    "from flwr_datasets import FederatedDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from fedntd.models import Net, apply_transforms, test, train\n",
    "\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"Standard Flower client for CNN training.\"\"\"\n",
    "\n",
    "    def __init__(self, trainloader, valloader) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.model = Net(num_classes=10)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        \"\"\"Change the parameters of the model using the given ones.\"\"\"\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def get_parameters(self, config: Dict[str, Scalar]):\n",
    "        \"\"\"Return the parameters of the current net.\"\"\"\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Implement distributed fit function for a given client.\"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
    "        optim = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=0.9)\n",
    "        train(\n",
    "            self.model,\n",
    "            self.trainloader,\n",
    "            optim,\n",
    "            epochs=epochs,\n",
    "            device=self.device,\n",
    "            tau=1.0,\n",
    "            beta=1.0,\n",
    "            num_classes=10,\n",
    "        )\n",
    "        return self.get_parameters({}), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
    "        \"\"\"Implement distributed evaluation for a given client.\"\"\"\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(self.model, self.valloader, device=self.device)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def get_client_fn(dataset: FederatedDataset):\n",
    "    \"\"\"Return a function to construct a client.\n",
    "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
    "    the strategy to participate.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> fl.client.Client:\n",
    "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
    "        client_dataset = dataset.load_partition(int(cid), \"train\")\n",
    "        client_dataset_splits = client_dataset.train_test_split(test_size=0.1)\n",
    "        trainset = client_dataset_splits[\"train\"]\n",
    "        valset = client_dataset_splits[\"test\"]\n",
    "        trainloader = DataLoader(\n",
    "            trainset.with_transform(apply_transforms), batch_size=32, shuffle=True\n",
    "        )\n",
    "        valloader = DataLoader(valset.with_transform(apply_transforms), batch_size=32)\n",
    "        return FlowerClient(trainloader, valloader).to_client()\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import flwr as fl\n",
    "import hydra\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "from flwr.common import Scalar\n",
    "from flwr_datasets import FederatedDataset\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "\n",
    "from fedntd.client import get_client_fn\n",
    "from fedntd.server import get_evaluate_fn\n",
    "from fedntd.utils import save_results_as_pickle, plot_metric_from_history\n",
    "\n",
    "\n",
    "@hydra.main(config_path=\"conf\", config_name=\"base\", version_base=None)\n",
    "def main(cfg: DictConfig) -> None:\n",
    "    \"\"\"Run the baseline.\n",
    "    Parameters\n",
    "    ----------\n",
    "    cfg : DictConfig\n",
    "        An omegaconf object that stores the hydra config.\n",
    "    \"\"\"\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    NUM_CLIENTS = 2\n",
    "\n",
    "    mnist_fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": NUM_CLIENTS})\n",
    "    centralized_testset = mnist_fds.load_full(\"test\")\n",
    "\n",
    "    def fit_config(server_round: int) -> Dict[str, Scalar]:\n",
    "        \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
    "        config: Dict[str, Scalar] = {\n",
    "            \"epochs\": 1,\n",
    "            \"lr\": 0.01,\n",
    "        }\n",
    "        return config\n",
    "\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        on_fit_config_fn=fit_config,\n",
    "        evaluate_fn=get_evaluate_fn(centralized_testset),\n",
    "    )\n",
    "\n",
    "    disable_progress_bar()\n",
    "\n",
    "    history = fl.simulation.start_simulation(\n",
    "        client_fn=get_client_fn(mnist_fds),\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=3),\n",
    "        strategy=strategy,\n",
    "        actor_kwargs={\"on_actor_init_fn\": disable_progress_bar},\n",
    "    )\n",
    "\n",
    "    print(\"................\")\n",
    "    print(history)\n",
    "\n",
    "    save_path = HydraConfig.get().runtime.output_dir\n",
    "\n",
    "    # save results as a Python pickle using a file_path\n",
    "    # the directory created by Hydra for each run\n",
    "    save_results_as_pickle(history, file_path=save_path, extra_results={})\n",
    "\n",
    "    # plot results and include them in the readme\n",
    "    # strategy_name = strategy.__class__.__name__\n",
    "    # file_suffix: str = (\n",
    "    #     f\"_{strategy_name}\"\n",
    "    #     f\"{'_iid' if cfg.dataset_config.iid else ''}\"\n",
    "    #     f\"{'_balanced' if cfg.dataset_config.balance else ''}\"\n",
    "    #     f\"{'_powerlaw' if cfg.dataset_config.power_law else ''}\"\n",
    "    #     f\"_C={cfg.num_clients}\"\n",
    "    #     f\"_B={cfg.batch_size}\"\n",
    "    #     f\"_E={cfg.num_epochs}\"\n",
    "    #     f\"_R={cfg.num_rounds}\"\n",
    "    #     f\"_mu={cfg.mu}\"\n",
    "    #     f\"_strag={cfg.stragglers_fraction}\"\n",
    "    # )\n",
    "\n",
    "    plot_metric_from_history(\n",
    "        history,\n",
    "        save_path,\n",
    "        # (file_suffix),\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
